{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scorecardpy as sc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nonconformist.cp import IcpClassifier\n",
    "from nonconformist.nc import ClassifierNc\n",
    "from nonconformist.nc import MarginErrFunc\n",
    "from nonconformist.nc import InverseProbabilityErrFunc\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.nc import ClassificationErrFunc\n",
    "\n",
    "\n",
    "\n",
    "def cost_matrix_Small(df):\n",
    "    '''Cost function for the dataset \"Small\". Assumption of 5% interest p.a.'''\n",
    "    cost_matrix = pd.DataFrame()\n",
    "    cost_matrix['false_positive'] = df['LoanAmount'] * df['Loan_Amount_Term'] / 12 *0.05 #5% p.a. interest assumed\n",
    "    cost_matrix['false_negative'] = df['LoanAmount']\n",
    "    return cost_matrix\n",
    "    \n",
    "def cost_matrix_German(df):\n",
    "    '''Cost function for the dataset \"German\". Mean monthly duration was rounded to 24.'''\n",
    "    cost_matrix = pd.DataFrame()\n",
    "    cost_matrix['false_positive'] = df['Duration_in_month'] /24 #mean is nearly 21, so /24 is approx 1\n",
    "    cost_matrix['false_negative'] = 4\n",
    "    return cost_matrix\n",
    "    \n",
    "def cost_matrix_Deloitte(df):\n",
    "    '''Cost function for the dataset \"Deloitte\". Assumption of term to be documented in months.'''\n",
    "    cost_matrix = pd.DataFrame()\n",
    "    cost_matrix['false_positive'] = df['Loan Amount'] * df['Interest Rate'] * df['Term'] /100 /12 #term seems to be in months\n",
    "    cost_matrix['false_negative'] = df['Loan Amount']\n",
    "    return cost_matrix\n",
    "    \n",
    "def cost_matrix_Large(df):\n",
    "    '''Cost function for the dataset \"Large\". Assumption of term to be documented in months, rate of interest in %.'''\n",
    "    cost_matrix = pd.DataFrame()\n",
    "    cost_matrix['false_positive'] = df['loan_amount'] * df['term'] / 12 * df['rate_of_interest'] / 100 + df['Upfront_charges']\n",
    "    cost_matrix['false_negative'] = df['loan_amount']\n",
    "    return cost_matrix\n",
    "    \n",
    "def cost_matrix_LC(df):\n",
    "    '''Cost function for the dataset \"LC\". Since term and iterest are not available for rejected applications, \n",
    "    the most frequent term in years and the average interest rate are assumed for every application.'''\n",
    "    cost_matrix = pd.DataFrame()\n",
    "    cost_matrix['false_positive'] = df['Amount Requested'] * 3 * 0.13 #most frequent term in years and average interest\n",
    "    cost_matrix['false_negative'] = df['Amount Requested']\n",
    "    return cost_matrix\n",
    "    \n",
    "def cost_loss(y_true, y_pred, cost_mat):\n",
    "    '''Cost Loss Function from Bahnsen (2016)'''\n",
    "    y_true = y_true.values.ravel()\n",
    "    y_pred = y_pred.values.ravel()\n",
    "    cost_mat = cost_mat.to_numpy()\n",
    "    cost = y_true * ((1 - y_pred) * cost_mat[:, 1]) #+ y_pred * cost_mat[:, 2]) fn\n",
    "    cost += (1 - y_true) * (y_pred * cost_mat[:, 0]) #+ (1 - y_pred) * cost_mat[:, 3]) fp\n",
    "    return np.sum(cost)\n",
    "\n",
    "def data_prep(start_, test_, name):\n",
    "    '''Data Preparation Function. Includes generating the cost efficient threshold, normalization of numerical features\n",
    "    and WoE transformation of categorical features.'''\n",
    "    \n",
    "    # Copies of dataframe inputs\n",
    "    start  = start_.copy()\n",
    "    test=test_.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use appropriate cost function\n",
    "    if name ==  'Small':\n",
    "        cost_matrix = cost_matrix_Small(start)\n",
    "        cost_matrix_test = cost_matrix_Small(test)\n",
    "    elif name ==  'German':\n",
    "        cost_matrix = cost_matrix_German(start)\n",
    "        cost_matrix_test = cost_matrix_German(test)\n",
    "    elif name ==  'Deloitte':\n",
    "        cost_matrix = cost_matrix_Deloitte(start)\n",
    "        cost_matrix_test = cost_matrix_Deloitte(test)\n",
    "    elif name ==  'Large':\n",
    "        cost_matrix = cost_matrix_Large(start)\n",
    "        cost_matrix_test = cost_matrix_Large(test)\n",
    "    elif name ==  'LC':\n",
    "        cost_matrix = cost_matrix_LC(start)\n",
    "        cost_matrix_test = cost_matrix_LC(test)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Calculate Bayes optimal threshold\n",
    "    threshold = np.mean( cost_matrix['false_positive']) / np.mean(cost_matrix['false_negative'] + cost_matrix['false_positive'])\n",
    "    \n",
    "    \n",
    "    # Ensure correct data type for each feature\n",
    "    for col in test.columns:\n",
    "        dtype = pd.api.types.infer_dtype(test[col])\n",
    "        if dtype == 'categorical':\n",
    "            test[col] = test[col].astype('category')\n",
    "        elif dtype == 'floating':\n",
    "            test[col] = test[col].astype('float')\n",
    "        elif dtype == 'integer':\n",
    "            test[col] = test[col].astype('float')\n",
    "        \n",
    "    for col in start.columns:\n",
    "        dtype = pd.api.types.infer_dtype(start[col])\n",
    "        if dtype == 'categorical':\n",
    "            start[col] = start[col].astype('category')\n",
    "        elif dtype == 'floating':\n",
    "            start[col] = start[col].astype('float')\n",
    "        elif dtype == 'integer':\n",
    "            start[col] = start[col].astype('float')\n",
    "     \n",
    "    # Drop features with only 1 feature\n",
    "    for col in start.columns:\n",
    "        if start[col].nunique() == 1:\n",
    "            start.drop(col, axis=1, inplace=True)\n",
    "            test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    # Select the categorical columns and transform to WoE\n",
    "    cat_cols = start.select_dtypes(include=['object', 'category']).columns\n",
    "    bins = sc.woebin(start, y=\"BAD\", x=cat_cols.tolist(), print_step=0, check_cate_num=False)\n",
    "    start_trans = sc.woebin_ply(start, bins, print_step=0)\n",
    "\n",
    "\n",
    "    # Select the numeric columns and standardize them\n",
    "    numeric_cols = start.drop(columns='BAD').select_dtypes(include=['float', 'int', 'uint8']).columns\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(start_trans[numeric_cols])\n",
    "    start_trans[numeric_cols] = scaler.transform(start_trans[numeric_cols])\n",
    "    \n",
    "    # Same procedur for test set\n",
    "    test_trans=test\n",
    "    test_trans[numeric_cols] = scaler.transform(test_trans[numeric_cols])\n",
    "    test_trans = sc.woebin_ply(test_trans, bins, print_step=0)\n",
    "\n",
    "    # If test set contained categories unavailable in the start set, replace its WoE with the most frequent one\n",
    "    for feature in test_trans.columns:\n",
    "        most_frequent_value = test_trans[feature].mode().values[0]\n",
    "        test_trans[feature].fillna(most_frequent_value, inplace=True)\n",
    "    \n",
    "    return start_trans, test_trans, cost_matrix, threshold, cost_matrix_test\n",
    "\n",
    "\n",
    "def no_al(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_):\n",
    "    '''Benchmark strategy of No Active Learning'''\n",
    "    \n",
    "    # Copies of used dataframes\n",
    "    start_= start.copy()\n",
    "    start_trans_ = start_trans.copy()\n",
    "    test_ = test.copy()\n",
    "    test_trans = test_trans_.copy()\n",
    "    \n",
    "    # Underlying model\n",
    "    LR = LogisticRegression(penalty='l1', solver='saga', random_state=0, class_weight='balanced')\n",
    "    LR.fit(start_trans_.drop(columns=['BAD']), start_trans_['BAD'])\n",
    "    \n",
    "    # Predict probabilities\n",
    "    test_['BAD_pred'] = LR.predict_proba(test_trans.drop(columns=['BAD']))[:, 1]\n",
    "    \n",
    "    test_['BAD'] = test_['BAD'].astype(int)\n",
    "    \n",
    "    # Assess performance\n",
    "    AUC = roc_auc_score(test_['BAD'],test_['BAD_pred'])\n",
    "    \n",
    "    ptest = test_[test_['BAD_pred']<0.5]\n",
    "    \n",
    "    if len(ptest) == 0 or len(ptest['BAD'].unique()) ==1:\n",
    "        PAUC = None\n",
    "    else:\n",
    "        PAUC = roc_auc_score(ptest['BAD'],ptest['BAD_pred'])\n",
    "        \n",
    "    BS = brier_score_loss(test_['BAD'], test_['BAD_pred'])\n",
    "\n",
    "\n",
    "    \n",
    "    # Round probabilites to classes\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] >= threshold_] = 1\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] < threshold_] = 0\n",
    "    test_['BAD_pred'] = test_['BAD_pred'].astype(int)\n",
    "   \n",
    "    # Assess Cost\n",
    "    Cost = cost_loss(test_['BAD'], test_['BAD_pred'], cost_matrix_test_)\n",
    "    metrics=[AUC, PAUC, BS, Cost, threshold_]\n",
    "\n",
    "    # Concat accepted applications to training data\n",
    "    goods_pred = test_[test_['BAD_pred']==0].drop(columns='BAD_pred')\n",
    "    \n",
    "    new_data = pd.concat([start, goods_pred])\n",
    "\n",
    "    return new_data, metrics\n",
    "\n",
    "def random_al(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_):\n",
    "    '''Active Learning strategy of selecting a random sample of AL instances'''\n",
    "    \n",
    "    # Copies of used dataframes\n",
    "    start_= start.copy()\n",
    "    start_trans_ = start_trans.copy()\n",
    "    test_ = test.copy()\n",
    "    test_trans = test_trans_.copy()\n",
    "    \n",
    "    # Underlying model\n",
    "    LR = LogisticRegression(penalty='l1', solver='saga', random_state=0, class_weight='balanced')\n",
    "    LR.fit(start_trans_.drop(columns=['BAD']), start_trans_['BAD'])\n",
    "    \n",
    "    # Predict probabilities\n",
    "    test_['BAD_pred'] = LR.predict_proba(test_trans.drop(columns=['BAD']))[:, 1]\n",
    "    \n",
    "    test_['BAD'] = test_['BAD'].astype(int)\n",
    "    \n",
    "    # Assess performance\n",
    "    AUC = roc_auc_score(test_['BAD'],test_['BAD_pred'])\n",
    "    \n",
    "    ptest = test_[test_['BAD_pred']<0.5]\n",
    "    \n",
    "    if len(ptest) == 0 or len(ptest['BAD'].unique()) ==1:\n",
    "        PAUC = None\n",
    "    else:\n",
    "        PAUC = roc_auc_score(ptest['BAD'],ptest['BAD_pred'])\n",
    "        \n",
    "    BS = brier_score_loss(test_['BAD'], test_['BAD_pred'])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Round probabilites to classes\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] >= threshold_] = 1\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] < threshold_] = 0\n",
    "    test_['BAD_pred'] = test_['BAD_pred'].astype(int)\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Randomly sample rejected applications of sample size of the BAD share of accepted applications and turn their prediction\n",
    "    # from BAD to GOOD\n",
    "    mask = test_['BAD_pred'] == 1\n",
    "    sample_size = int(np.mean(start['BAD']) * len(test_[test_['BAD_pred'] ==0]))\n",
    "    sample_size=min(sample_size, len(test_[test_['BAD_pred'] ==1]))\n",
    "    al_customers = np.random.choice(test_[mask].index, size=sample_size, replace=False)\n",
    "\n",
    "    # Change the selected 1s to 0s in the dataframe\n",
    "    test_.loc[al_customers, 'BAD_pred'] = 0\n",
    "    \n",
    "    # Assess Cost\n",
    "    Cost = cost_loss(test_['BAD'], test_['BAD_pred'], cost_matrix_test_)\n",
    "    metrics=[AUC, PAUC, BS, Cost, threshold_]\n",
    "\n",
    "    # Concat accepted applications to training data\n",
    "    goods_pred = test_[test_['BAD_pred']==0].drop(columns='BAD_pred')\n",
    "    new_data = pd.concat([start_, goods_pred])\n",
    "\n",
    "    return new_data, metrics\n",
    "\n",
    "def benchmark_ri(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_):\n",
    "    '''Reject Inference Benchmark of selecting the same random sample of AL instances, \n",
    "    but marking them as defaulted without handing the loan'''\n",
    "    \n",
    "    # Copies of used dataframes\n",
    "    start_= start.copy()\n",
    "    start_trans_ = start_trans.copy()\n",
    "    test_ = test.copy()\n",
    "    test_trans = test_trans_.copy()\n",
    "    \n",
    "    # Underlying model\n",
    "    LR = LogisticRegression(penalty='l1', solver='saga', random_state=0, class_weight='balanced')\n",
    "    LR.fit(start_trans_.drop(columns=['BAD']), start_trans_['BAD'])\n",
    "    \n",
    "    # Predict probabilities\n",
    "    test_['BAD_pred'] = LR.predict_proba(test_trans.drop(columns=['BAD']))[:, 1]\n",
    "    \n",
    "    test_['BAD'] = test_['BAD'].astype(int)\n",
    "    \n",
    "    # Assess performance\n",
    "    AUC = roc_auc_score(test_['BAD'],test_['BAD_pred'])\n",
    "    \n",
    "    ptest = test_[test_['BAD_pred']<0.5]\n",
    "    \n",
    "    if len(ptest) == 0 or len(ptest['BAD'].unique()) ==1:\n",
    "        PAUC = None\n",
    "    else:\n",
    "        PAUC = roc_auc_score(ptest['BAD'],ptest['BAD_pred'])\n",
    "        \n",
    "    BS = brier_score_loss(test_['BAD'], test_['BAD_pred'])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Round probabilites to classes\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] >= threshold_] = 1\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] < threshold_] = 0\n",
    "    test_['BAD_pred'] = test_['BAD_pred'].astype(int)\n",
    "    \n",
    "    \n",
    "    # Assess Cost\n",
    "    Cost = cost_loss(test_['BAD'], test_['BAD_pred'], cost_matrix_test_)\n",
    "    metrics=[AUC, PAUC, BS, Cost, threshold_]\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Randomly sample rejected applications of sample size of 20% of accepted applications and label them as BAD\n",
    "    mask = test_['BAD_pred'] == 1\n",
    "    sample_size = int(np.mean(start['BAD']) * len(test_[test_['BAD_pred'] ==0]))\n",
    "    sample_size=min(sample_size, len(test_[test_['BAD_pred'] ==1]))\n",
    "    ri_customers = np.random.choice(test_[mask].index, size=sample_size, replace=False)\n",
    "\n",
    "    # Save RI applications\n",
    "    test_.loc[ri_customers, 'BAD'] = 1\n",
    "    RI = test_.loc[ri_customers].drop(columns='BAD_pred')\n",
    "\n",
    "    # Concat accepted applications and RI applications to training data\n",
    "    goods_pred = test_[test_['BAD_pred']==0].drop(columns='BAD_pred')\n",
    "    new_data = pd.concat([start_, goods_pred, RI])\n",
    "\n",
    "    return new_data, metrics\n",
    "\n",
    "\n",
    "def row_normalized(input_array):\n",
    "    '''Normalize probabilities to yield a sum of 1.'''\n",
    "    row_sums = np.sum(input_array, axis=1)\n",
    "    output_array = input_array / row_sums[:, np.newaxis]\n",
    "    return output_array\n",
    "\n",
    "\n",
    "\n",
    "def icp(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_, error_func):\n",
    "    '''Active Learning strategy of using an Inductive Conformal Predictor for assessing Confidence of predicted BADs.\n",
    "    Reqires and error function of the class type to be put in for the error_func parameter.'''\n",
    "    \n",
    "    # Copies of used dataframes\n",
    "    start_= start.copy()\n",
    "    start_trans_ = start_trans.copy()\n",
    "    test_ = test.copy()\n",
    "    test_trans = test_trans_.copy()\n",
    "    \n",
    "    # Split the transformed training data into training and calibration data\n",
    "    start_trans_split, cal_trans = train_test_split(\n",
    "        start_trans, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Underlying model\n",
    "    LR = LogisticRegression(penalty='l1', solver='saga', random_state=0, class_weight='balanced')\n",
    "    adapter = ClassifierAdapter(LR)\n",
    "    nc = ClassifierNc(adapter, error_func)\n",
    "    \n",
    "    # Inductive Classifier\n",
    "    icp = IcpClassifier(nc, smoothing=False)\n",
    "    icp.fit(start_trans_split.drop(columns='BAD').values, start_trans_split['BAD'].values)\n",
    "    icp.calibrate(cal_trans.drop(columns='BAD').values, cal_trans['BAD'].values)\n",
    "\n",
    "    # Predict probabilities and normalize them\n",
    "    preds =icp.predict(test_trans.drop(columns='BAD').values)\n",
    "    preds = row_normalized(preds)\n",
    "    \n",
    "    test_['BAD_pred'] = preds[:, 1]\n",
    "    \n",
    "    test_['BAD'] = test_['BAD'].astype(int)\n",
    "    \n",
    "    # Assess perfomance\n",
    "    AUC = roc_auc_score(test_['BAD'],test_['BAD_pred'])\n",
    "    \n",
    "    ptest = test_[test_['BAD_pred']<0.5]\n",
    "    #PAUC = roc_auc_score(ptest['BAD'],ptest['BAD_pred'])\n",
    "    if len(ptest) == 0 or len(ptest['BAD'].unique()) ==1:\n",
    "        PAUC = None\n",
    "    else:\n",
    "        # calculate AUC score\n",
    "        PAUC = roc_auc_score(ptest['BAD'],ptest['BAD_pred'])\n",
    "        \n",
    "    BS = brier_score_loss(test_['BAD'], test_['BAD_pred'])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Round probabilites to classes\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] >= threshold_] = 1\n",
    "    test_['BAD_pred'].loc[test_['BAD_pred'] < threshold_] = 0\n",
    "    test_['BAD_pred'] = test_['BAD_pred'].astype(int)\n",
    "    \n",
    "    # Assess confidence of predictions\n",
    "    test_['pred_conf'] = icp.predict_conf(test_trans.drop(columns='BAD').values)[:, 1]\n",
    "\n",
    "    # Sample the least confident rejected applications of sample size of the BAD share of accepted applications and turn their prediction\n",
    "    # from BAD to GOOD\n",
    "    sample_size = int(np.mean(start['BAD']) * len(test_[test_['BAD_pred'] ==0]))\n",
    "    sample_size=min(sample_size, len(test_[test_['BAD_pred'] ==1]))\n",
    "    \n",
    "    rows_to_switch = test_[test_['BAD_pred'] == 1].nsmallest(sample_size, 'pred_conf').index\n",
    "\n",
    "    # Switch the selected rows from 0s to 1s in the binary column\n",
    "    test_.loc[rows_to_switch, 'BAD_pred'] = 0\n",
    "    \n",
    "    # Assess Cost\n",
    "    Cost = cost_loss(test_['BAD'], test_['BAD_pred'], cost_matrix_test_)\n",
    "    metrics=[AUC, PAUC, BS, Cost, threshold_]\n",
    "\n",
    "    # Concat accpeted applications to training data\n",
    "    goods_pred = test_[test_['BAD_pred']==0].drop(columns=['BAD_pred', 'pred_conf'])\n",
    "    new_data = pd.concat([start_, goods_pred])\n",
    "\n",
    "    return new_data, metrics\n",
    "\n",
    "\n",
    "class NearestNeighbourMargin(ClassificationErrFunc):\n",
    "    '''Nearest Neighbour Margin Error Function. Combines the ideas of Margin Error Function and Nearest Neighbour prediction'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NearestNeighbourMargin, self).__init__()\n",
    "\n",
    "    def apply(self, prediction, y):\n",
    "        prob = np.zeros(y.size, dtype=np.float32)\n",
    "        ratios=[]\n",
    "        for i, y_ in enumerate(y):\n",
    "            if y_ >= prediction.shape[1]:\n",
    "                prob[i] = 0\n",
    "            else:        \n",
    "                prob[i] = prediction[i, int(y_)]\n",
    "                # distance to nearest neighbour with different class\n",
    "                diff_neigh= np.min(np.absolute(prob[i] - prediction[:,int(1-y_)]))\n",
    "                # distance to nearest neighbour with same class\n",
    "                same_neigh= np.min(np.absolute(prob[i] - prediction[:,int(y_)]))\n",
    "                ratio = same_neigh / diff_neigh \n",
    "                ratios.append(ratio)\n",
    "        return np.array(ratios)\n",
    "\n",
    "    \n",
    "def icp_prob (start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_):\n",
    "    '''Active Learning strategy of using an Inductive Conformal Predictor for assessing Confidence of predicted BADs.\n",
    "    Inverse Probability Error Function used as Error Function'''\n",
    "    \n",
    "    return icp(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_, InverseProbabilityErrFunc())\n",
    " \n",
    "def icp_nnmargin(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_):\n",
    "    '''Active Learning strategy of using an Inductive Conformal Predictor for assessing Confidence of predicted BADs.\n",
    "    Nearest Neighbour Margin Error Function used as Error Function''' \n",
    "    return icp(start, start_trans, test, test_trans_, threshold_, cost_matrix_, cost_matrix_test_, NearestNeighbourMargin())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
